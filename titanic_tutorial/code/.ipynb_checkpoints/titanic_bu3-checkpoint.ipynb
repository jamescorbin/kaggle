{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "data_name = \"data\"\n",
    "train_bn = \"train.csv\"\n",
    "test_bn = \"test.csv\"\n",
    "results_bn = \"results.csv\"\n",
    "\n",
    "full_bn = \"full.csv\"\n",
    "\n",
    "proj_dir = os.path.abspath(\n",
    "        os.path.join(os.path.abspath(__name__), os.pardir, os.pardir))\n",
    "data_dir = os.path.join(proj_dir, data_name)\n",
    "train_fn = os.path.join(data_dir, train_bn)\n",
    "test_fn = os.path.join(data_dir, test_bn)\n",
    "results_fn = os.path.join(data_dir, results_bn)\n",
    "\n",
    "full_fn = os.path.join(data_dir, full_bn)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise OSError(\"Data directory not properly setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "class LabelEncoderExt(preprocessing.LabelEncoder):\n",
    "    \n",
    "    UNK = \"UNK\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def fit(self, y):\n",
    "        \n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = np.array(y)\n",
    "        assert (len(y.shape) == 1), \"Require 1D array\"\n",
    "        y = np.concatenate((y, np.array([self.UNK])))\n",
    "        super().fit(y)\n",
    "        \n",
    "    def transform(self, y):\n",
    "        \n",
    "        y[~np.isin(y, self.classes_, assume_unique=True)] = self.UNK\n",
    "        return super().transform(y)\n",
    "    \n",
    "    def fit_transform(self, y):\n",
    "        \n",
    "        self.fit(y)\n",
    "        return self.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    df_train = pd.read_csv(train_fn)\n",
    "except OSError as e:\n",
    "    print(\"Training file missing.\")\n",
    "try:\n",
    "    df_test = pd.read_csv(test_fn)\n",
    "except OSError as e:\n",
    "    print(\"Test file missing.\")\n",
    "    \n",
    "try:\n",
    "    df_full = pd.read_csv(full_fn, quotechar='\"')\n",
    "except OSError as e:\n",
    "    print(\"Test file missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "pd.concat([df_train, df_test]).sort_values(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_test.join(df_full.set_index(\"name\"), how=\"left\", on=\"Name\").drop_duplicates(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Name\"\n",
    "sex = \"Sex\"\n",
    "emb = \"Embarked\"\n",
    "cabin = \"Cabin\"\n",
    "age = \"Age\"\n",
    "fare = \"Fare\"\n",
    "ticket = \"Ticket\"\n",
    "sib = \"SibSp\"\n",
    "par = \"Parch\"\n",
    "pclass = \"Pclass\"\n",
    "\n",
    "dummy_cols = [\n",
    "        pclass, \n",
    "        #ticket,\n",
    "        name, cabin, emb]\n",
    "pid = \"PassengerId\"\n",
    "dep_vars = [\"Survived\"]\n",
    "indices = [pid]\n",
    "ind_vars = [x for x in df_train.columns if x not in (dep_vars+indices+[ticket])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_encoding(df):\n",
    "    \n",
    "    reg_ex = \"\\w+\\s?\\w*(\\.)\"\n",
    "    reg = re.compile(reg_ex)\n",
    "    f = lambda x: x.split(',')[1].strip()\n",
    "    g = lambda x: reg.match(x).group()\n",
    "    h = lambda x: x[0] if len(x) > 0 else ''\n",
    "    thresh = 0.01\n",
    "    unk = \"UNK\"\n",
    "    \n",
    "    tmp = df.groupby(ticket).count()\n",
    "    df['ticket_count'] = df[ticket].apply(lambda x: tmp.at[x, pid])\n",
    "    \n",
    "    df[[cabin]] = df[cabin].fillna('')    \n",
    "    \n",
    "    numb_cab = lambda x: len(x.split())\n",
    "    df[\"num_cab\"] = df[cabin].apply(numb_cab)\n",
    "    \n",
    "        # extra\n",
    "    f2 = lambda x: {'': '', \"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"D\", \"F\": \"D\", \"G\": \"D\", \"T\": \"D\"}[x] \n",
    "    \n",
    "    df[name] = df[name].apply(f).apply(g)\n",
    "    freq = df[name].value_counts(normalize=True)\n",
    "    k = lambda x: x if freq[x] >= thresh else unk\n",
    "    df[name] = df[name].apply(k)\n",
    "    \n",
    "    df[cabin] = df[cabin].apply(h).apply(f2)\n",
    "    \n",
    "    df[sex] = df[sex].apply(h)\n",
    "    \n",
    "    #df[par] = df[par] + df[sib] + 1\n",
    "    #df = df.drop(sib, axis=1)\n",
    "    \n",
    "    #df[fare] = df[fare]/df[par]\n",
    "    #df[fare] = np.divide(df[fare].values, df[\"num_cab\"].values, where=df[\"num_cab\"]!=0)\n",
    "    #df[fare] = np.divide(df[fare].values, df[par], where=df[\"num_cab\"]==0)\n",
    "    # extra\n",
    "\n",
    "    ticket_prefix = lambda x: 1 if len(x.split()) > 1 else 0\n",
    "    ticket_prefix = lambda x: len(x.split()) - 1\n",
    "    df[ticket] = df[ticket].apply(ticket_prefix) \n",
    "    \n",
    "    df[\"single\"] = df[par].apply(lambda x: 1 if x==0 else 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_encoders(df):\n",
    "   \n",
    "    enc_name = LabelEncoderExt()\n",
    "    enc_sex = preprocessing.LabelEncoder()\n",
    "    enc_emb = preprocessing.LabelEncoder()\n",
    "    enc_cabin = preprocessing.LabelEncoder()\n",
    "\n",
    "    enc_name.fit(df[name])\n",
    "    enc_sex.fit(df[sex].dropna())\n",
    "    enc_emb.fit(df[emb].dropna())\n",
    "    enc_cabin.fit(df[cabin])\n",
    "    enc_dict = {name: enc_name, sex: enc_sex, emb: enc_emb, cabin: enc_cabin}\n",
    " \n",
    "    scl_age = preprocessing.StandardScaler()\n",
    "    scl_age.fit(df[[age]].dropna().values)\n",
    "    scl_fare = preprocessing.StandardScaler()\n",
    "    scl_fare.fit(df[[fare]].dropna().values)\n",
    "    scl = {age: scl_age, fare: scl_fare}\n",
    "        \n",
    "    return enc_dict, scl\n",
    "\n",
    "\n",
    "def scale(df, scl):\n",
    "    \n",
    "    df.loc[df[[age]].dropna().index, age] = scl[age].transform(df[age].dropna().values)\n",
    "    df.loc[df[[fare]].dropna().index, fare] = scl.transform(df[fare].dropna().values)    \n",
    "    return df\n",
    "\n",
    "\n",
    "def naive_bayes_data_fill(df, enc_dict, clf=None):\n",
    "\n",
    "    df.loc[df[emb].dropna().index, emb] = enc_dict[emb].transform(df[emb].dropna().values)\n",
    "    df.loc[:, sex] = enc_dict[sex].transform(df[sex].values)\n",
    "    df.loc[:, cabin] = enc_dict[cabin].transform(df[cabin].values)\n",
    "    df.loc[:, name] = enc_dict[name].transform(df[name].values)\n",
    "    \n",
    "    tmp = df[[pclass, sex, par, emb]].dropna()\n",
    "    index = df.index.isin(tmp.index)\n",
    "    \n",
    "    X = tmp[[pclass, sex, par]].values.astype(int)\n",
    "    Y = tmp[emb].values.astype(int)\n",
    "    tmp2 = df.loc[~index, [pclass, sex, par]]\n",
    "    if len(tmp2) > 0:\n",
    "        if clf is None:\n",
    "            clf = MultinomialNB()\n",
    "        clf.fit(X, Y)\n",
    "        df.loc[~index, emb] = clf.predict(tmp2)\n",
    "    \n",
    "    return df, clf\n",
    "\n",
    "\n",
    "def mean_data_fill(df):\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    group = [pclass, \"num_cab\", emb, par, \"single\"]\n",
    "    nan_fares = df[fare].isnull()\n",
    "    \n",
    "    tmp1 = df[group+[fare]].dropna()\n",
    "    clf = SVR()\n",
    "    reg = clf.fit(tmp1[group].values, tmp1[fare].values)\n",
    "    df.loc[nan_fares, fare] = reg.predict(df.loc[nan_fares, group].values)\n",
    "     \n",
    "    #tmp1 = df.groupby(group).mean()[[fare]]\n",
    "    #tmp3 = df.loc[nan_fares][group]\n",
    "    #ind = pd.MultiIndex.from_arrays(tmp3.values.T, names=tmp1.index.names)\n",
    "    #df.loc[nan_fares, fare] = tmp1.loc[ind, fare].fillna(0).values\n",
    "    \n",
    "    \n",
    "    group2 = [pclass, name, par, emb]\n",
    "    nan_ages = df[age].isnull()\n",
    "    \n",
    "    tmp1 = df[group2+[age]].dropna()\n",
    "    reg = clf.fit(tmp1[group2].values, tmp1[age].values)\n",
    "    df.loc[nan_ages, age] = reg.predict(df.loc[nan_ages, group2].values)\n",
    "    \n",
    "    #tmp1 = df.groupby(group2).mean()[[age]]\n",
    "    #tmp2 = df.loc[nan_ages][group2]\n",
    "    #ind = pd.MultiIndex.from_arrays(tmp2.values.T, names=tmp1.index.names)\n",
    "    #df.loc[nan_ages, age] = tmp1.loc[ind, age].fillna(0).values\n",
    "    \n",
    "    return df.iloc[:df1.shape[0]], df.iloc[df1.shape[0]:]\n",
    "\n",
    "def preprocess(df, enc_dict=None, scl=None, clf=None):\n",
    "    \n",
    "    df = pre_encoding(df)\n",
    "    if enc_dict is None:\n",
    "        enc_dict, scl = build_encoders(df)\n",
    "    df = scale(df, scl)\n",
    "    df, clf = naive_bayes_data_fill(df, enc_dict, clf=clf)\n",
    "    \n",
    "    #df = mean_data_fill(df)\n",
    "    \n",
    "\n",
    "    return df, enc_dict, scl, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (1045,) could not be broadcast to indexing result of shape (1711,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6fba93d75445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-cc32c069bb33>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(df, enc_dict, scl, clf)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menc_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0menc_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_encoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes_data_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cc32c069bb33>\u001b[0m in \u001b[0;36mscale\u001b[0;34m(df, scl)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfare\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfare\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfare\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                         \u001b[0;31m# setting with a list, recoerces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m                         \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0;31m# we have an equal len list/ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    960\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setitem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;31m# set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (1045,) could not be broadcast to indexing result of shape (1711,)"
     ]
    }
   ],
   "source": [
    "df_X, enc_dict, scl, clf = preprocess(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra(df):\n",
    "\n",
    "    min_age = 14\n",
    "    df[\"child\"] = df[age].apply(lambda x: 1 if x <= scl.transform([[min_age, 0]])[0, 0] else 0)\n",
    "    df[\"child_women\"] = df[\"child\"] + (1 - df[\"Sex\"])\n",
    "    df[\"child_women\"] = df[[\"child\", \"Sex\"]].max(axis=1).values\n",
    "    df = df.drop([\"child\", \"Sex\"], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = extra(df_train)\n",
    "df_test = extra(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tmp = df_train[[fare, cabin]]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(tmp[cabin], tmp[fare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(df_train, columns=dummy_cols).drop(dep_vars+indices, axis=1)\n",
    "X_test = pd.get_dummies(df_test, columns=dummy_cols).drop(indices, axis=1)\n",
    "\n",
    "X_test = X_test.join(pd.DataFrame({x: 0 for x in X_train.columns if x not in X_test.columns}, index=X_test.index))\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "Y_train = df_train[dep_vars]\n",
    "\n",
    "Y_test = t[[dep_vars[0].lower()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        \"n_estimators\": [100],\n",
    "        #\"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [3, 4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "rf_clf = RandomForestClassifier()\n",
    "clf = GridSearchCV(rf_clf, parameters, cv=5)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "clf.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "#pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "results = pd.DataFrame({indices[0]: df_test[indices[0]].values, dep_vars[0]: pred})\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, pred))\n",
    "pd.DataFrame(confusion_matrix(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results.to_csv(results_fn, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
