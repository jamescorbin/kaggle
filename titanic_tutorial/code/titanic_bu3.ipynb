{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_name = \"data\"\n",
    "train_bn = \"train.csv\"\n",
    "test_bn = \"test.csv\"\n",
    "results_bn = \"results.csv\"\n",
    "\n",
    "full_bn = \"full.csv\"\n",
    "\n",
    "proj_dir = os.path.abspath(\n",
    "        os.path.join(os.path.abspath(__name__), os.pardir, os.pardir))\n",
    "data_dir = os.path.join(proj_dir, data_name)\n",
    "train_fn = os.path.join(data_dir, train_bn)\n",
    "test_fn = os.path.join(data_dir, test_bn)\n",
    "results_fn = os.path.join(data_dir, results_bn)\n",
    "\n",
    "full_fn = os.path.join(data_dir, full_bn)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise OSError(\"Data directory not properly setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "class LabelEncoderExt(preprocessing.LabelEncoder):\n",
    "    \n",
    "    UNK = \"UNK\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def fit(self, y):\n",
    "        \n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = np.array(y)\n",
    "        assert (len(y.shape) == 1), \"Require 1D array\"\n",
    "        y = np.concatenate((y, np.array([self.UNK])))\n",
    "        super().fit(y)\n",
    "        \n",
    "    def transform(self, y):\n",
    "        \n",
    "        y[~np.isin(y, self.classes_, assume_unique=True)] = self.UNK\n",
    "        return super().transform(y)\n",
    "    \n",
    "    def fit_transform(self, y):\n",
    "        \n",
    "        self.fit(y)\n",
    "        return self.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    df_train = pd.read_csv(train_fn)\n",
    "except OSError as e:\n",
    "    print(\"Training file missing.\")\n",
    "try:\n",
    "    df_test = pd.read_csv(test_fn)\n",
    "except OSError as e:\n",
    "    print(\"Test file missing.\")\n",
    "    \n",
    "try:\n",
    "    df_full = pd.read_csv(full_fn, quotechar='\"')\n",
    "except OSError as e:\n",
    "    print(\"Test file missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "pd.concat([df_train, df_test]).sort_values(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_test.join(df_full.set_index(\"name\"), how=\"left\", on=\"Name\").drop_duplicates(subset=[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Name\"\n",
    "sex = \"Sex\"\n",
    "emb = \"Embarked\"\n",
    "cabin = \"Cabin\"\n",
    "age = \"Age\"\n",
    "fare = \"Fare\"\n",
    "ticket = \"Ticket\"\n",
    "sib = \"SibSp\"\n",
    "par = \"Parch\"\n",
    "pclass = \"Pclass\"\n",
    "\n",
    "family = \"family\"\n",
    "\n",
    "dummy_cols = [\n",
    "        pclass, \n",
    "        #ticket,\n",
    "        \"fam_size\",\n",
    "        name, \n",
    "        cabin, \n",
    "        emb]\n",
    "pid = \"PassengerId\"\n",
    "dep_vars = [\"Survived\"]\n",
    "indices = [pid]\n",
    "ind_vars = [x for x in df_train.columns if x not in (dep_vars+indices+[ticket])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_encoding(df):\n",
    "    \n",
    "    reg_ex = \"\\w+\\s?\\w*(\\.)\"\n",
    "    reg = re.compile(reg_ex)\n",
    "    f = lambda x: x.split(',')[1].strip()\n",
    "    g = lambda x: reg.match(x).group()\n",
    "    h = lambda x: x[0] if len(x) > 0 else ''\n",
    "    thresh = 0.01\n",
    "    unk = \"UNK\"\n",
    "    \n",
    "    df[sex] = df[sex].apply(h)\n",
    "    \n",
    "    df[name] = df[name].apply(f).apply(g)\n",
    "    freq = df[name].value_counts(normalize=True)\n",
    "    k = lambda x: x if freq[x] >= thresh else unk\n",
    "    df[name] = df[name].apply(k)    \n",
    "    \n",
    "    tmp = df.groupby(ticket).count()\n",
    "    df['ticket_count'] = df[ticket].apply(lambda x: tmp.at[x, pid])\n",
    "\n",
    "    df[cabin] = df[cabin].fillna('')\n",
    "    numb_cab = lambda x: len(x.split())\n",
    "    df.loc[df[cabin].notnull(), \"num_cab\"] = (\n",
    "            df.loc[df[cabin].notnull(), cabin].apply(numb_cab)) \n",
    "    mapping = {'': '', 'A': 'A', 'B': 'B', 'C': 'B',\n",
    "               'D': 'D', 'E':'D', 'F':'F', 'G': 'F', 'T': 'A'}\n",
    "    comb = lambda x: mapping[x]\n",
    "    df.loc[df[cabin].notnull(), cabin] = (\n",
    "            df.loc[df[cabin].notnull(), cabin].apply(h).apply(comb))\n",
    "    \n",
    "    df[family] = df[par] + df[sib] + 1\n",
    "    \n",
    "    df[\"fam_per_tickets\"] = df[family]/df[\"ticket_count\"]\n",
    "    #df[fare] = df[fare]/df[par]\n",
    "    #df[fare] = np.divide(df[fare].values, df[\"num_cab\"].values, where=df[\"num_cab\"]!=0)\n",
    "    #df[fare] = np.divide(df[fare].values, df[par], where=df[\"num_cab\"]==0)\n",
    "    #df[fare] = df[fare]/df['ticket_count']\n",
    "    # extra\n",
    "\n",
    "    #ticket_prefix = lambda x: 1 if len(x.split()) > 1 else 0\n",
    "    #ticket_prefix = lambda x: len(x.split()) - 1\n",
    "    #df[ticket] = df[ticket].apply(ticket_prefix) \n",
    "    \n",
    "    df[\"single\"] = df[family].apply(lambda x: 1 if x==1 else 0)\n",
    "    \n",
    "    f_size = {1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 2, 7: 2, 8: 3, 9: 3, 10: 3, 11: 3}\n",
    "    df[\"fam_size\"] = df[family].apply(lambda x: f_size[x])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_encoders(df):\n",
    "   \n",
    "    enc_name = LabelEncoderExt()\n",
    "    enc_sex = preprocessing.LabelEncoder()\n",
    "    enc_emb = preprocessing.LabelEncoder()\n",
    "    enc_cabin = preprocessing.LabelEncoder()\n",
    "\n",
    "    enc_name.fit(df[name])\n",
    "    enc_sex.fit(df[sex].dropna())\n",
    "    enc_emb.fit(df[emb].dropna())\n",
    "    enc_cabin.fit(df[cabin].dropna())\n",
    "    enc_dict = {name: enc_name, sex: enc_sex, emb: enc_emb, cabin: enc_cabin}\n",
    " \n",
    "    scl_age = preprocessing.StandardScaler()\n",
    "    scl_age.fit(df[[age]].dropna().values)\n",
    "    scl_fare = preprocessing.StandardScaler()\n",
    "    scl_fare.fit(df[[fare]].dropna().values)\n",
    "    scl = {age: scl_age, fare: scl_fare}\n",
    "        \n",
    "    return enc_dict, scl\n",
    "\n",
    "\n",
    "def scale(df, scl):\n",
    "    \n",
    "    df.loc[df[[age]].dropna().index, age] = (\n",
    "            scl[age].transform(df[[age]].dropna().values))\n",
    "    df.loc[df[[fare]].dropna().index, fare] = (\n",
    "            scl[fare].transform(df[[fare]].dropna().values))    \n",
    "    return df\n",
    "\n",
    "\n",
    "def naive_bayes_data_fill(df, enc_dict):\n",
    "\n",
    "    df.loc[df[emb].dropna().index, emb] = (\n",
    "            enc_dict[emb].transform(df[emb].dropna().values))\n",
    "    df.loc[:, sex] = enc_dict[sex].transform(df[sex].values)\n",
    "    df.loc[df[cabin].dropna().index, cabin] = (\n",
    "            enc_dict[cabin].transform(df[cabin].dropna().values))\n",
    "    df.loc[:, name] = enc_dict[name].transform(df[name].values)\n",
    "    \n",
    "    tmp = df[[pclass, sex, par, emb]].dropna()\n",
    "    index = df.index.isin(tmp.index)\n",
    "    \n",
    "    X = tmp[[pclass, sex, par]].values.astype(int)\n",
    "    Y = tmp[emb].values.astype(int)\n",
    "    tmp2 = df.loc[~index, [pclass, sex, par]]\n",
    "    if len(tmp2) > 0:\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X, Y)\n",
    "        df.loc[~index, emb] = clf.predict(tmp2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def mean_data_fill(df):\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    group = [pclass, emb]\n",
    "    nan_fares = df[fare].isnull()\n",
    "    \n",
    "    '''\n",
    "    tmp = df[group+[fare]].dropna()\n",
    "    clf = SVR()\n",
    "    reg = clf.fit(tmp[group].values, tmp[fare].values)\n",
    "    df.loc[nan_fares, fare] = reg.predict(df.loc[nan_fares, group].values)\n",
    "    ''' \n",
    "    \n",
    "    tmp = df.groupby(group).mean()[[fare]]\n",
    "    tmp2 = df.loc[nan_fares][group]\n",
    "    ind = pd.MultiIndex.from_arrays(tmp2.values.T, names=tmp.index.names)\n",
    "    df.loc[nan_fares, fare] = tmp.loc[ind, fare].fillna(0).values\n",
    "    \n",
    "    \n",
    "    group = [name, \"fam_size\"]\n",
    "    nan_ages = df[age].isnull()\n",
    "    \n",
    "    '''\n",
    "    tmp1 = df[group+[age]].dropna()\n",
    "    clf = SVR()\n",
    "    reg = clf.fit(tmp1[group].values, tmp1[age].values)\n",
    "    df.loc[nan_ages, age] = reg.predict(df.loc[nan_ages, group].values)\n",
    "    '''\n",
    "    \n",
    "    tmp1 = df.groupby(group).mean()[[age]]\n",
    "    tmp2 = df.loc[nan_ages][group]\n",
    "    ind = pd.MultiIndex.from_arrays(tmp2.values.T, names=tmp1.index.names)\n",
    "    df.loc[nan_ages, age] = tmp1.loc[ind, age].fillna(0).values\n",
    "\n",
    "    '''\n",
    "    group = [pclass, emb, par, sib, fare]\n",
    "    nan_cabin = df[cabin].isnull()\n",
    "    \n",
    "    tmp = df.loc[~nan_cabin, group+[cabin]]\n",
    "    from sklearn.svm import LinearSVC\n",
    "    clf = LinearSVC()\n",
    "    #clf = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
    "    #clf = MultinomialNB()\n",
    "    #reg = clf.fit(tmp[group].values, tmp[[x for x in tmp.columns if x not in cabin]].values)\n",
    "    reg = clf.fit(tmp[group].values, tmp[cabin].values.astype(int))\n",
    "    df.loc[nan_cabin, cabin] = reg.predict(df.loc[nan_cabin, group].values)\n",
    "    df.loc[:, cabin] = df[cabin].astype(int)\n",
    "    '''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess(df, enc_dict=None, scl=None):\n",
    "    \n",
    "    df = pre_encoding(df)\n",
    "    if enc_dict is None:\n",
    "        enc_dict, scl = build_encoders(df)\n",
    "    df = scale(df, scl)\n",
    "    df = naive_bayes_data_fill(df, enc_dict)\n",
    "    \n",
    "    df = mean_data_fill(df)\n",
    "    \n",
    "    min_age = 10\n",
    "    df[\"child\"] = df[age].apply(lambda x: 1 if x <= scl[age].transform([[min_age]])[0, 0] else 0)\n",
    "    #df[\"child_women\"] = df[\"child\"] | (1 - df[\"Sex\"])\n",
    "\n",
    "    #df = df.drop([\"num_cab\"], axis=1)\n",
    "    #df = df.drop([sex, \"child\"], axis=1)\n",
    "    df = df.drop([ticket], axis=1)\n",
    "    df = df.drop([par, sib, family], axis=1)\n",
    "    \n",
    "    return df, enc_dict, scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X, enc_dict, scl= preprocess(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_X.iloc[:df_train.shape[0]]\n",
    "df_test = df_X.iloc[df_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tmp = df_train[[fare, cabin]]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(tmp[cabin], tmp[fare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(df_train, columns=dummy_cols).drop(dep_vars+indices, axis=1)\n",
    "X_test = pd.get_dummies(df_test, columns=dummy_cols).drop(indices, axis=1)\n",
    "\n",
    "X_test = X_test.join(pd.DataFrame({x: 0 for x in X_train.columns if x not in X_test.columns}, index=X_test.index))\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "Y_train = df_train[dep_vars]\n",
    "\n",
    "Y_test = t[[dep_vars[0].lower()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Age', 'Fare', 'ticket_count', 'num_cab', 'fam_per_tickets',\n",
       "       'single', 'child', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'fam_size_0',\n",
       "       'fam_size_1', 'fam_size_2', 'fam_size_3', 'Name_0', 'Name_1', 'Name_2',\n",
       "       'Name_3', 'Name_4', 'Cabin_0', 'Cabin_1', 'Cabin_2', 'Cabin_3',\n",
       "       'Cabin_4', 'Embarked_0', 'Embarked_1', 'Embarked_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        \"n_estimators\": [100],\n",
    "        #\"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [3, 4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#clf =  GradientBoostingClassifier(learning_rate=0.11)\n",
    "\n",
    "#clf = GridSearchCV(rf_clf, parameters, cv=5)\n",
    "clf = RandomForestClassifier(n_estimators=700, max_depth=5,\n",
    "                            max_leaf_nodes=32,\n",
    "                            #criterion=\"gini\",\n",
    "                            min_samples_split=4, min_samples_leaf=5)\n",
    "clf.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "#pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "results = pd.DataFrame({indices[0]: df_test[indices[0]].values, dep_vars[0]: pred})\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, pred))\n",
    "pd.DataFrame(confusion_matrix(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results.to_csv(results_fn, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
