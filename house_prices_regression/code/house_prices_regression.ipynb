{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import xgboost\n",
    "import sklearn.svm\n",
    "import sklearn.linear_model\n",
    "import sklearn.ensemble\n",
    "import sklearn.gaussian_process\n",
    "import sklearn.kernel_ridge\n",
    "import sklearn.tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = 160\n",
    "\n",
    "log = logging.getLogger(name=__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "logging.captureWarnings(True)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "stream_handler.setFormatter(formatter)\n",
    "log.addHandler(stream_handler)\n",
    "\n",
    "log.info(f\"Python version: {sys.version}\")\n",
    "log.info(f\"Numpy version: {np.__version__}\")\n",
    "log.info(f\"Pandas version: {pd.__version__}\")\n",
    "log.info(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "log.info(f\"Plotly version: {plotly.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bn = \"data\"\n",
    "data_dir = os.path.abspath(\n",
    "    os.path.join(__name__, os.pardir, os.pardir, data_bn)\n",
    ")\n",
    "\n",
    "log.info(f\"Data directory: {data_dir}\")\n",
    "\n",
    "train_bn = \"train.csv\"\n",
    "test_bn = \"test.csv\"\n",
    "train_fn = os.path.join(data_dir, train_bn)\n",
    "test_fn = os.path.join(data_dir, test_bn)\n",
    "\n",
    "df_train = pd.read_csv(train_fn)\n",
    "df_test = pd.read_csv(test_fn)\n",
    "\n",
    "log.info(f\"Training data shape: {df_train.shape}\")\n",
    "log.info(f\"Test data shape: {df_test.shape}\")\n",
    "\n",
    "train_pts = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f\"Number of training dataset columns: {len(df_train.columns)}.\")\n",
    "df_train.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_fn = os.path.join(data_dir, \"data_description.txt\")\n",
    "\n",
    "with open(description_fn, 'r') as f:\n",
    "    desc = [x for x in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_re = re.compile(\"\\w+(?:)\")\n",
    "\n",
    "feat_search = []\n",
    "\n",
    "for i, line in enumerate(desc):\n",
    "    a = feat_re.match(line)\n",
    "    if a:\n",
    "        feat_search.append((i, a.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_search[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = []\n",
    "cont_feats = []\n",
    "\n",
    "STEP = 2\n",
    "\n",
    "for i, couple in enumerate(feat_search[:-1]):\n",
    "    if feat_search[i+1][0] - couple[0] > STEP:\n",
    "        cat_feats.append(couple[1])\n",
    "    else:\n",
    "        cont_feats.append(couple[1])\n",
    "        \n",
    "if len(desc) - feat_search[-1][0] > STEP:\n",
    "    cat_feats.append(feat_search[-1][1])\n",
    "else:\n",
    "    cont_feats.append(feat_search[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cont_feats.remove(\"Kitchen\")\n",
    "    cont_feats.append(\"KitchenAbvGr\")\n",
    "except ValueError as e:\n",
    "    log.error(e)\n",
    "try:\n",
    "    cont_feats.remove(\"Bedroom\")\n",
    "    cont_feats.append(\"BedroomAbvGr\")\n",
    "except ValueError as e:\n",
    "    log.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = \"UNK\"\n",
    "RANK = \"rank\"\n",
    "NUMBER = \"number\"\n",
    "FREQUENCY = \"frequency\"\n",
    "\n",
    "\n",
    "class OrdinalEncoderExt(sklearn.preprocessing.OrdinalEncoder):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 top_n=None, \n",
    "                 count_thresh=None, \n",
    "                 freq_thresh=None, \n",
    "                 categories=\"auto\", \n",
    "                 **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(OrdinalEncoderExt, self).__init__(\n",
    "            categories=categories,\n",
    "            **kwargs\n",
    "        )\n",
    "        if top_n is not None:\n",
    "            self.criterion = RANK\n",
    "            try:\n",
    "                self.criterion_val = int(top_n)\n",
    "            except ValueError as e:\n",
    "                log.error(e)\n",
    "        elif count_thresh is not None:\n",
    "            self.criterion = NUMBER\n",
    "            try:\n",
    "                self.criterion_val = int(count_thresh)\n",
    "            except ValueError as e:\n",
    "                log.error(e)\n",
    "        elif freq_thresh is not None:\n",
    "            self.criterion = FREQUENCY\n",
    "            try:\n",
    "                self.criterion_val = float(freq_thresh)\n",
    "            except ValueError as e:\n",
    "                log.error(e)\n",
    "        else:\n",
    "            self.criterion = \"\"\n",
    "            self.criterion_val = None\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            X = np.array(X)\n",
    "        except ValueError as e:\n",
    "            log.error(e)\n",
    "        assert (len(X.shape)==2), \"Require 2D array\"\n",
    "        \n",
    "        X = X.astype(str)\n",
    "        \n",
    "        Y = np.full(X.shape, \"\", dtype=\"U20\")\n",
    "        for j in range(X.shape[1]):\n",
    "            unique_elem, elem_locs, elem_counts = (\n",
    "                np.unique(\n",
    "                    X[:, j],\n",
    "                    return_inverse=True,\n",
    "                    return_counts=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if self.criterion == RANK:\n",
    "                a = np.argpartition(elem_counts, self.criterion_val)\n",
    "                for t in a:\n",
    "                    Y[elem_locs[t], j] = unique_elem[t]\n",
    "            elif self.criterion == NUMBER:\n",
    "                for i, t in np.ndenumerate(elem_counts):\n",
    "                    if t >= self.criterion_val:\n",
    "                        Y[elem_locs[i], j] = unique_elem[i]\n",
    "            elif self.criterion == FREQUENCY:\n",
    "                for i, t in np.ndenumerate(elem_counts):\n",
    "                    if t/x.shape[0] >= self.criterion_val:\n",
    "                        Y[elem_locs[i], j] = unique_elem[i]\n",
    "            else:\n",
    "                Y[:, j] = X[:, j]\n",
    "            Y[np.where(Y[:, j]==''), j] = UNK\n",
    "\n",
    "        tmp = np.full(X.shape[1], UNK).reshape((1, -1))\n",
    "        Y = np.append(Y, tmp, axis=0)\n",
    "\n",
    "        super(OrdinalEncoderExt, self).fit(Y)\n",
    "        \n",
    "        return 0\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        X = X.astype(str)\n",
    "        for i in range(X.shape[1]):\n",
    "            X[~np.isin(X[:, i], self.categories_[i]), i] = UNK\n",
    "            \n",
    "        return super(OrdinalEncoderExt, self).transform(X).astype(int)\n",
    "\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_data = df_train[cat_feats]\n",
    "train_cat_data.fillna(\"\", inplace=True)\n",
    "\n",
    "test_cat_data = df_test[cat_feats]\n",
    "test_cat_data.fillna(\"\", inplace=True)\n",
    "\n",
    "enc = OrdinalEncoderExt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_vals = (\n",
    "    pd.DataFrame(\n",
    "        enc.fit_transform(train_cat_data.values), \n",
    "        columns=train_cat_data.columns,\n",
    "    )\n",
    ")\n",
    "\n",
    "test_cat_vals = pd.DataFrame(enc.transform(test_cat_data.values), columns=test_cat_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_vals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_vals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    f\"{train_cat_data.columns[i]}_{x}\" \n",
    "        for i, col in enumerate(enc.categories_) for x in col\n",
    "]\n",
    "train_bin_enc = pd.DataFrame()\n",
    "test_bin_enc = pd.DataFrame()\n",
    "\n",
    "\n",
    "for j, cat in enumerate(train_cat_vals.columns):\n",
    "    for i, col in enumerate(enc.categories_[j]):\n",
    "        train_bin_enc[f\"{cat}_{col}\"] = train_cat_vals[cat].apply(lambda x: 1 if x==i else 0)\n",
    "        test_bin_enc[f\"{cat}_{col}\"] = test_cat_vals[cat].apply(lambda x: 1 if x==i else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat_scl = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "train_bin_enc = pd.DataFrame(\n",
    "    cat_scl.fit_transform(train_bin_enc.values),\n",
    "    columns=train_bin_enc.columns,\n",
    ")\n",
    "\n",
    "test_bin_enc = pd.DataFrame(\n",
    "    cat_scl.transform(test_bin_enc.values),\n",
    "    columns=test_bin_enc.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bin_enc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bin_enc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cont_data = df_train[cont_feats]\n",
    "test_cont_data = df_test[cont_feats]\n",
    "\n",
    "scl = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "train_cont_vals = pd.DataFrame(\n",
    "    scl.fit_transform(train_cont_data.values),\n",
    "    columns=train_cont_data.columns,\n",
    ")\n",
    "test_cont_vals = pd.DataFrame(\n",
    "    scl.transform(test_cont_data.values),\n",
    "    columns=train_cont_data.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cont_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cont_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cont_vals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cont_vals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_cont_vals.join(train_bin_enc)\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "log.info(f\"Total number of independent features before projection: {X.shape[1]}\")\n",
    "\n",
    "X_test = test_cont_vals.join(test_bin_enc)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition \n",
    "\n",
    "n_components = 150\n",
    "\n",
    "pca = sklearn.decomposition.PCA(\n",
    "    n_components=n_components,\n",
    "    svd_solver='randomized',\n",
    "    whiten=True).fit(X)\n",
    "\n",
    "X = pd.DataFrame(pca.transform(X))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train[[y_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "hist = go.Histogram(\n",
    "    x=Y_train[y_col].values, \n",
    "    xbins=dict(\n",
    "        start=0,\n",
    "        end=Y_train[y_col].max(),\n",
    "        size=10000,\n",
    "    ),\n",
    ")\n",
    "fig.add_trace(hist)\n",
    "\n",
    "fig.update_layout(\n",
    "    go.Layout(\n",
    "        xaxis = dict(\n",
    "            rangeslider = {'visible': False},\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y_col = \"log_y\"\n",
    "\n",
    "Y_train[log_y_col] = np.log(Y_train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "hist = go.Histogram(\n",
    "    x=Y_train[log_y_col].values, \n",
    "    xbins=dict(\n",
    "        start=0,\n",
    "        end=Y_train[log_y_col].max(),\n",
    "        size=0.10,\n",
    "    ),\n",
    ")\n",
    "fig.add_trace(hist)\n",
    "\n",
    "fig.update_layout(\n",
    "    go.Layout(\n",
    "        xaxis = dict(\n",
    "            rangeslider = {'visible': False},\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scl = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "Y = pd.DataFrame(y_scl.fit_transform(Y_train[[log_y_col]].values), columns=Y_train[[log_y_col]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.join(Y)\n",
    "\n",
    "Z_corr = Z.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in Z.columns[:2]:\n",
    "    if col not in (y_col, log_y_col):\n",
    "        \n",
    "        cor_x = np.linspace(Z[col].min(), Z[col].max(), 3)\n",
    "        s = Z_corr.at[log_y_col, col]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        trace = go.Scatter(x=Z[col], y=Z[log_y_col], mode=\"markers\", text=Z.index)\n",
    "        trace_cor = go.Scatter(x=cor_x, y=s*cor_x, mode=\"lines\")\n",
    "        \n",
    "        fig.add_trace(trace)\n",
    "        fig.add_trace(trace_cor)\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=1400,\n",
    "            height=1200,\n",
    "            title=dict(text=f\"{col} vs. {y_col}\"),\n",
    "            xaxis_title=dict(text=col),\n",
    "            yaxis_title=dict(text=y_col),\n",
    "        )\n",
    "        plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    sklearn.linear_model.LinearRegression(),\n",
    "]\n",
    "\n",
    "xgb_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        #n_estimators=[100, 110, 150],\n",
    "        #max_depth=[5, 7],\n",
    "        learning_rate=[None, 1e-4, 1e-2],\n",
    "        booster=[\"gbtree\", \"gblinear\", \"dart\"],\n",
    "        reg_alpha=[None, 1e-5, 1e-3],\n",
    "        reg_lambda=[None, 1e-5, 1e-3],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [xgboost.XGBRegressor(**params) for params in xgb_param_grid]\n",
    ")\n",
    "\n",
    "lsvr_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        C=[1, 2, 0.5],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.svm.LinearSVR(**params) for params in lsvr_param_grid]\n",
    ")\n",
    "\n",
    "svr_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        C=[1, 2, 0.5],\n",
    "        kernel=[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "        gamma=[\"scale\", 0.01],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.svm.SVR(**params) for params in svr_param_grid]\n",
    ")\n",
    "        \n",
    "kernel_ridge_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        alpha=[1, 2, 1e-1],\n",
    "        gamma=[None, 1, 0.1],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.kernel_ridge.KernelRidge(**params) \n",
    "        for params in kernel_ridge_param_grid\n",
    "    ]\n",
    ")\n",
    "        \n",
    "elastic_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        alpha=[2, 1, 0.5],\n",
    "        l1_ratio=[0.5, 1, 0.1],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.linear_model.ElasticNet(**params) \n",
    "        for params in elastic_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "gauss_process_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        kernel=[\n",
    "            None, \n",
    "            sklearn.gaussian_process.kernels.Matern(),\n",
    "            sklearn.gaussian_process.kernels.DotProduct(),\n",
    "            sklearn.gaussian_process.kernels.RationalQuadratic(),\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.gaussian_process.GaussianProcessRegressor(**params)\n",
    "        for params in gauss_process_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "elastic_cv_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        l1_ratio=[0.5, 0.1, 0.7, 0.9, 0.95, 1],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.linear_model.ElasticNetCV(**params) \n",
    "        for params in elastic_cv_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "gradient_boosting_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        n_estimators=[100, 150],\n",
    "        criterion=[\"friedman_mse\", \"mse\", \"mae\"],\n",
    "        max_depth=[3, 5],\n",
    "        max_features=[\n",
    "            #\"auto\",\n",
    "            \"sqrt\", \"log2\"],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.ensemble.GradientBoostingRegressor(**params)\n",
    "        for params in gradient_boosting_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "random_forest_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        n_estimators=[100, 150],\n",
    "        criterion=[\"mse\", \"mae\"],\n",
    "        max_depth=[None, 5],\n",
    "        max_features=[\n",
    "            #\"auto\",\n",
    "            \"sqrt\", \"log2\"],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.ensemble.RandomForestRegressor(**params)\n",
    "        for params in random_forest_param_grid\n",
    "    ]\n",
    ")\n",
    "    \n",
    "ridge_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        alpha=[1, 2, 0.5],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.linear_model.Ridge(**params)\n",
    "         for params in ridge_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "bayes_adr_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        alpha_1=[1e-6, 1e-5],\n",
    "        alpha_2=[1e-6, 1e-5],\n",
    "        lambda_1=[1e-6, 1e-5],\n",
    "        lambda_2=[1e-6, 1e-5],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.linear_model.ARDRegression(**params)\n",
    "        for params in bayes_adr_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "sgd_linear_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        eta0=[0.01, 0.005],\n",
    "        power_t=[0.25, 0.2],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.linear_model.SGDRegressor(**params)\n",
    "        for params in sgd_linear_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "ada_boost_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        base_estimator=[\n",
    "            None,\n",
    "            sklearn.tree.DecisionTreeRegressor(max_depth=4),\n",
    "        ],\n",
    "        loss=[\"linear\", \"square\", \"exponential\"],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.ensemble.AdaBoostRegressor(**params)\n",
    "        for params in ada_boost_param_grid\n",
    "    ]\n",
    ")\n",
    "\n",
    "bagging_param_grid = sklearn.model_selection.ParameterGrid(\n",
    "    dict(\n",
    "        n_estimators=[10, 20],\n",
    "        max_features=[1.0, 0.2],\n",
    "        bootstrap=[True, False],\n",
    "    )\n",
    ")\n",
    "models.extend(\n",
    "    [sklearn.ensemble.BaggingRegressor(**params)\n",
    "        for params in bagging_param_grid\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pred_cols = [f\"model_{i:03d}\" for i in range(len(models))]\n",
    "f = lambda x: np.exp(y_scl.inverse_transform(x))\n",
    "    \n",
    "scores = []\n",
    "\n",
    "#splts = 2\n",
    "#kf = sklearn.model_selection.KFold(n_splits=splts)\n",
    "#kf_cols = [f\"k{i//2}_scl\" if i % 2 ==0 else f\"k{i//2}\" for i in range(2*splts)]\n",
    "kf_cols = [\"k0_scl\", \"k0\"]\n",
    "\n",
    "for model in models:\n",
    "    t1 = time.perf_counter()\n",
    "    row = []\n",
    "    \n",
    "    #for train_index, test_index in kf.split(X.values, Y.values):\n",
    "    #    model.fit(X.loc[train_index], Y.loc[train_index])\n",
    "    if True:\n",
    "        X_train_split, X_test_split, y_train_split, y_test_split = sklearn.model_selection.train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train_split, y_train_split)\n",
    "        \n",
    "        pred = model.predict(X)\n",
    "        r2 = sklearn.metrics.r2_score(Y[log_y_col], pred)\n",
    "        try:\n",
    "            r2t = sklearn.metrics.r2_score(f(Y[log_y_col]), f(pred))\n",
    "        except ValueError as e:\n",
    "            log.error(e)\n",
    "            r2t = np.nan\n",
    "        row.append(r2)\n",
    "        row.append(r2t)\n",
    "    t2 = time.perf_counter()\n",
    "    row.append(t2-t1)\n",
    "    scores.append(row)\n",
    "    log.info(f\"{str(model)[:15]} -- time elapsed: {t2-t1:5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(scores, index=pred_cols, columns=kf_cols+[\"time\"])\n",
    "\n",
    "cv_df[\"name\"] = [str(model) for model in models]\n",
    "cv_df['params'] = [model.get_params() for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.sort_values(by=['k0_scl'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = pd.read_csv(os.path.join(data_dir, \"true_submission.csv\"))\n",
    "\n",
    "true_labels[log_y_col] = np.log(true_labels[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = cv_df.sort_values(by=['k0'], ascending=False).index[128]\n",
    "model = models[int(model_name[-3:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Id\": df_test[\"Id\"], \"SalePrice\": f(model.predict(X_test)).reshape((-1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn = os.path.join(data_dir, \"results.csv\")\n",
    "#results.to_csv(results_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.sqrt(\n",
    "    sklearn.metrics.mean_squared_error(true_labels[log_y_col], np.log(results[y_col]))\n",
    ")\n",
    "log.info(f\"RMSE of log: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(400):\n",
    "    model_name = cv_df.sort_values(by=['k0'], ascending=False).index[i]\n",
    "    model = models[int(model_name[-3:])]\n",
    "    results = pd.DataFrame({\"Id\": df_test[\"Id\"], \"SalePrice\": f(model.predict(X_test)).reshape((-1))})\n",
    "    val = np.sqrt(\n",
    "        sklearn.metrics.mean_squared_error(true_labels[log_y_col], np.log(results[y_col]))\n",
    "    )\n",
    "    log.info(f\"{i} RMSE of log: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
