{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 23:06:56,365 - nlp_disaster_tweets - INFO - Python version: 3.8.10 (default, Nov 26 2021, 20:14:08) \n",
      "[GCC 9.3.0]\n",
      "2022-03-07 23:06:56,366 - nlp_disaster_tweets - INFO - Numpy version: 1.19.5\n",
      "2022-03-07 23:06:56,366 - nlp_disaster_tweets - INFO - Pandas version: 1.2.1\n",
      "2022-03-07 23:06:56,366 - nlp_disaster_tweets - INFO - Scikit-learn version: 1.0.2\n",
      "2022-03-07 23:06:56,367 - nlp_disaster_tweets - INFO - TensorFlow version: 2.6.0\n",
      "2022-03-07 23:06:56,367 - nlp_disaster_tweets - INFO - tensorflow.random seed: 1\n"
     ]
    }
   ],
   "source": [
    "import nlp_disaster_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jec/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "out = nlp_disaster_tweets.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>at</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds the reason this earthquake may allah for...</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place being notified o...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number people receive wildfires evacuation ord...</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding bridge collapse nearb...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recipient recipient out control wild fires cal...</td>\n",
       "      <td></td>\n",
       "      <td>@aria_ahrary @thetawniest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number utc number km volcano hawaii http</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating an e bike collided a car ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest homes razed northern california wildfir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword location                                               text  \\\n",
       "0        NaN      NaN  deeds the reason this earthquake may allah for...   \n",
       "1        NaN      NaN              forest fire near la ronge sask canada   \n",
       "2        NaN      NaN  residents asked shelter place being notified o...   \n",
       "3        NaN      NaN  number people receive wildfires evacuation ord...   \n",
       "4        NaN      NaN  got sent photo ruby alaska smoke wildfires pou...   \n",
       "...      ...      ...                                                ...   \n",
       "7608     NaN      NaN  two giant cranes holding bridge collapse nearb...   \n",
       "7609     NaN      NaN  recipient recipient out control wild fires cal...   \n",
       "7610     NaN      NaN           number utc number km volcano hawaii http   \n",
       "7611     NaN      NaN  police investigating an e bike collided a car ...   \n",
       "7612     NaN      NaN  latest homes razed northern california wildfir...   \n",
       "\n",
       "                 hashtag                         at  href  \n",
       "0            #earthquake                                0  \n",
       "1                                                       0  \n",
       "2                                                       0  \n",
       "3             #wildfires                                0  \n",
       "4     #alaska #wildfires                                0  \n",
       "...                  ...                        ...   ...  \n",
       "7608                                                    1  \n",
       "7609                      @aria_ahrary @thetawniest     0  \n",
       "7610                                                    1  \n",
       "7611                                                    0  \n",
       "7612                                                    1  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(out[\"text\"].str.split(\" \").tolist())\n",
    "t = out[\"text\"].str.split(\" \").tolist()\n",
    "max_width = len(max(t, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0e51f064ded0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#word_enc, num_unique_words, word_cols = transform_data(df_full)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#tokenizer, num_unique_words, word_cols = tf_tokenizer(df_full, text, 1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_unique_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "#word_enc, num_unique_words, word_cols = transform_data(df_full)\n",
    "#tokenizer, num_unique_words, word_cols = tf_tokenizer(df_full, text, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    X_train, \n",
    "    epochs=8,\n",
    "    validation_data=X_valid,\n",
    "    callbacks=[\n",
    "        #tensorboard_callback, \n",
    "        early_stopping,],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(X_unpad)\n",
    "Y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pred = pd.DataFrame(Y_train_pred, columns=y_cols)\n",
    "df_train_pred = df_train_pred.apply(np.round).astype({x: int for x in y_cols})\n",
    "df_train_pred[target] = df_train_pred[\"target_1\"]\n",
    "df_train_pred.drop(y_cols, inplace=True, axis=1)\n",
    "df_train_pred[\"id\"] = df_train[\"id\"].values\n",
    "df_train_pred = df_train_pred[[\"id\", target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred = pd.DataFrame(Y_test_pred, columns=y_cols)\n",
    "df_test_pred = df_test_pred.apply(np.round).astype({x: int for x in y_cols})\n",
    "df_test_pred[target] = df_test_pred[\"target_1\"]\n",
    "df_test_pred.drop(y_cols, inplace=True, axis=1)\n",
    "df_test_pred.drop(\n",
    "    list(df_test_pred.index[df_train.shape[0]:]),\n",
    "    inplace=True, axis=0,\n",
    ")\n",
    "df_test_pred[\"id\"] = df_test[\"id\"].values\n",
    "df_test_pred = df_test_pred[[\"id\", target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"\\n\" +\n",
    "    sklearn.metrics.classification_report(\n",
    "        df_train[target],\n",
    "        df_train_pred[target],\n",
    "        target_names=[\"Not disaster\", \"Disaster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Training accuracy score {}.\".format(\n",
    "    sklearn.metrics.accuracy_score(df_train[target], df_train_pred[target])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = data_dir\n",
    "results_bn = \"results.csv\"\n",
    "results_fn = os.path.join(output_dir, results_bn)\n",
    "\n",
    "df_test_pred.to_csv(results_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save(os.path.join(tfboard_dir, \"model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
